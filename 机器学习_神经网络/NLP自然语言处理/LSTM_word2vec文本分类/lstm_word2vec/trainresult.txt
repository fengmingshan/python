lstm_wordemb.py 主要是使用了keras的embedding层来做word2vec,然后依然是lstm模型对评论数据进行情感分析（注：没有进行去停用词的操作，代码来自苏大神https://kexue.fm/archives/3863）
lstm_word2vec.py主要是用gensim训练word2vec，然后使用keras的lstm模型对评论数据进行情感分析
svm_word2vec.py主要是用gensim训练word2vec，然后使用sklearn的svm模型对评论数据进行情感分析
将传统与神经网络模型进行对比，代码大部分非我自己所写，出自https://github.com/BUPTLdy/Sentiment-Analysis这位大神之手，我只是进行了小部分修改，例如添加了去停用词的部分。
在理解代码的过程中发现了一些比较好的博文：
https://buptldy.github.io/2016/07/20/2016-07-20-sentiment%20analysis/
http://blog.sina.com.cn/s/blog_1450ac3c60102x79x.html
https://kexue.fm/archives/3863
https://zybuluo.com/hanbingtao/note/581764
https://juejin.im/entry/5acc23f26fb9a028d1416bb3

从训练结果来看，svm准确率能达到86%，而gensim+lstm能达到90%，同时，keras的embedding+lstm在训练集的准确率达到99%,测试集准确率90%
并没有像其原文所说的那样达到92%（可能lstm模型这个还需要调整下）
keras的embedding+lstm训练以及训练结果：
Using TensorFlow backend.
loading data...
Building prefix dict from /data/liuhua/env3.5/lib/python3.5/site-packages/jieba/dict.txt ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.927044153213501 seconds.
Prefix dict has been built succesfully.
train model ...
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 100, 256)          3666432   
_________________________________________________________________
lstm_1 (LSTM)                (None, 128)               197120    
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129       
_________________________________________________________________
activation_1 (Activation)    (None, 1)                 0         
=================================================================
Total params: 3,863,681
Trainable params: 3,863,681
Non-trainable params: 0
_________________________________________________________________
15000/15000 [==============================] - 17s - loss: 0.6158 - acc: 0.6491     
Epoch 2/30
15000/15000 [==============================] - 15s - loss: 0.4970 - acc: 0.7779     
Epoch 3/30
15000/15000 [==============================] - 15s - loss: 0.4545 - acc: 0.8301     
Epoch 4/30
15000/15000 [==============================] - 15s - loss: 0.5026 - acc: 0.7873     
Epoch 5/30
15000/15000 [==============================] - 15s - loss: 0.5037 - acc: 0.7700     
Epoch 6/30
15000/15000 [==============================] - 15s - loss: 0.4052 - acc: 0.8293     
Epoch 7/30
15000/15000 [==============================] - 15s - loss: 0.3180 - acc: 0.8798     
Epoch 8/30
15000/15000 [==============================] - 15s - loss: 0.2457 - acc: 0.9145     
Epoch 9/30
15000/15000 [==============================] - 15s - loss: 0.1785 - acc: 0.9421     
Epoch 10/30
15000/15000 [==============================] - 15s - loss: 0.1361 - acc: 0.9617     
Epoch 11/30
15000/15000 [==============================] - 15s - loss: 0.0994 - acc: 0.9740     
Epoch 12/30
15000/15000 [==============================] - 15s - loss: 0.0898 - acc: 0.9773     
Epoch 13/30
15000/15000 [==============================] - 15s - loss: 0.0758 - acc: 0.9829     
Epoch 14/30
15000/15000 [==============================] - 15s - loss: 0.0707 - acc: 0.9845     
Epoch 15/30
15000/15000 [==============================] - 15s - loss: 0.0598 - acc: 0.9873     
Epoch 16/30
15000/15000 [==============================] - 15s - loss: 0.0522 - acc: 0.9901     
Epoch 17/30
15000/15000 [==============================] - 15s - loss: 0.0476 - acc: 0.9903     
Epoch 18/30
15000/15000 [==============================] - 15s - loss: 0.0451 - acc: 0.9906     
Epoch 19/30
15000/15000 [==============================] - 15s - loss: 0.0432 - acc: 0.9910     
Epoch 20/30
15000/15000 [==============================] - 15s - loss: 0.0407 - acc: 0.9909     
Epoch 21/30
15000/15000 [==============================] - 15s - loss: 0.0424 - acc: 0.9912     
Epoch 22/30
15000/15000 [==============================] - 15s - loss: 0.3663 - acc: 0.8371     
Epoch 23/30
15000/15000 [==============================] - 15s - loss: 0.1031 - acc: 0.9705     
Epoch 24/30
15000/15000 [==============================] - 15s - loss: 0.0601 - acc: 0.9839     
Epoch 25/30
15000/15000 [==============================] - 15s - loss: 0.0626 - acc: 0.9839     
Epoch 26/30
15000/15000 [==============================] - 15s - loss: 0.0460 - acc: 0.9855     
Epoch 27/30
15000/15000 [==============================] - 15s - loss: 0.0384 - acc: 0.9893     
Epoch 28/30
15000/15000 [==============================] - 15s - loss: 0.0368 - acc: 0.9893     
Epoch 29/30
15000/15000 [==============================] - 15s - loss: 0.0294 - acc: 0.9924     
Epoch 30/30
15000/15000 [==============================] - 15s - loss: 0.0352 - acc: 0.9901     
6016/6105 [============================>.] - ETA: 0saccuracy is 
[0.4336619986802413, 0.90810810762970884]
load data and train model cost time : 824.59
load data and train model cost time : 5.059999999999945

gensim+lstm训练以及测试结果（测试语料：str = '屏幕较差，拍照也很粗糙。'）
Using TensorFlow backend.

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 100, 300)          2141100   
_________________________________________________________________
lstm_1 (LSTM)                (None, 50)                70200     
_________________________________________________________________
dropout_1 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
_________________________________________________________________
activation_1 (Activation)    (None, 1)                 0         
=================================================================

Test score: [0.53292876407062173, 0.90011862418829758]

屏幕较差，拍照也很粗糙。  positive



svm训练以及测试结果（测试语料：str = '屏幕较差，拍照也很粗糙。'）
[LibSVM]0.860696517413
屏幕较差，拍照也很粗糙。
[ 0.]
